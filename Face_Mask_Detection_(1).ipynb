{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face_Mask_Detection (1).ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mohit1052/Face-Mask-Detection/blob/main/Face_Mask_Detection_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viytAnMTdxQx"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4L6iBwkSfsBe"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.applications.resnet50 import preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from keras.layers import Dense, Flatten,Conv2D,Dropout,SeparableConv2D,MaxPooling2D\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1SYNhbGh75Y"
      },
      "source": [
        "my_new_model = Sequential()\n",
        "my_new_model.add(Conv2D(32,(7,7),activation='relu',input_shape=(224,224,3)))\n",
        "my_new_model.add(MaxPooling2D((2,2)))\n",
        "my_new_model.add(Dropout(0.2))\n",
        "my_new_model.add(Conv2D(64,(5,5),activation='relu'))\n",
        "my_new_model.add(MaxPooling2D((2,2)))\n",
        "my_new_model.add(Dropout(0.2))\n",
        "\n",
        "my_new_model.add(Conv2D(32,(3,3),activation='relu'))\n",
        "my_new_model.add(MaxPooling2D((2,2)))\n",
        "my_new_model.add(Dropout(0.3))\n",
        "\n",
        "my_new_model.add(Conv2D(16,(3,3),activation='relu'))\n",
        "my_new_model.add(MaxPooling2D((2,2)))\n",
        "my_new_model.add(Dropout(0.3))\n",
        "\n",
        "my_new_model.add(Flatten())\n",
        "my_new_model.add(Dense(16,activation='relu'))\n",
        "my_new_model.add(Dropout(0.5))\n",
        "my_new_model.add(Dense(2, activation='softmax'))\n",
        "# Indicate whether the first layer should be trained/changed or not.\n",
        "my_new_model.layers[0].trainable = False  \n",
        "\n",
        "my_new_model.compile(optimizer='adam', \n",
        "                     loss='categorical_crossentropy', \n",
        "                     metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m0tUFTrBXbe"
      },
      "source": [
        "my_new_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi3H87oBiFWE"
      },
      "source": [
        "image_size = 224\n",
        "data_generator = ImageDataGenerator(featurewise_center=True,\n",
        "    featurewise_std_normalization=True,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    samplewise_center=False,\n",
        "    samplewise_std_normalization=False,\n",
        "    zca_whitening=False,\n",
        "    zca_epsilon=1e-06,\n",
        "    brightness_range=None,\n",
        "    shear_range=0.0,\n",
        "    zoom_range=0.0,\n",
        "    channel_shift_range=0.0,\n",
        "    fill_mode=\"nearest\",\n",
        "    cval=0.0,\n",
        "    vertical_flip=False,\n",
        "    rescale=1.0/255.0,\n",
        "    preprocessing_function=None,\n",
        "    data_format=None,\n",
        "    validation_split=0.2,\n",
        "    dtype=None)\n",
        "\n",
        "train_generator = data_generator.flow_from_directory(\n",
        "                                        directory=r\"/content/gdrive/MyDrive/dataset1\",\n",
        "                                        target_size=(image_size, image_size),\n",
        "                                        subset='training',\n",
        "                                        batch_size=10,\n",
        "                                        shuffle=True,\n",
        "                                        class_mode='categorical')\n",
        "validation_generator = data_generator.flow_from_directory(\n",
        "                                        directory=r\"/content/gdrive/MyDrive/dataset1\",\n",
        "                                        target_size=(image_size, image_size),\n",
        "                                        subset='validation',\n",
        "                                        shuffle=True,\n",
        "                                        batch_size=10,\n",
        "                                        class_mode='categorical')\n",
        "\n",
        "classes = ['without_mask', 'with_mask']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n48a1uWbCurT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5jRITowBezT"
      },
      "source": [
        "fit_stats = my_new_model.fit_generator(generator = train_generator,\n",
        "                                steps_per_epoch = len(train_generator),\n",
        "                                epochs =20,\n",
        "                                validation_data = validation_generator,\n",
        "                                validation_steps=1)\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqWSmvsok_P4"
      },
      "source": [
        "plt.plot(fit_stats.history['loss'],'g^',label='Training Loss')\n",
        "plt.plot(fit_stats.history['val_loss'],'r--',label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.plot(fit_stats.history['accuracy'],'go',label='Training Accuracy')\n",
        "plt.plot(fit_stats.history['val_accuracy'],'r--',label='Validation Accuracy')\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpLoNt7NvSMZ"
      },
      "source": [
        "lab = validation_generator.classes\n",
        "pred= my_new_model.predict(validation_generator)\n",
        "\n",
        "predicted_class_indices=np.argmax(pred,axis=1)\n",
        "\n",
        "labels = (validation_generator.class_indices)\n",
        "labels2 = dict((v,k) for k,v in labels.items())\n",
        "predictions = [labels2[k] for k in predicted_class_indices]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihwmIBujtghl"
      },
      "source": [
        "lab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldHL6GRwBBqI"
      },
      "source": [
        "lab.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3JI5NaN4jFf"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, mean_absolute_error, precision_score, recall_score\n",
        "\n",
        "rc = roc_curve(predicted_class_indices,lab)\n",
        "cf_matrix = confusion_matrix(predicted_class_indices,lab)\n",
        "cf_report = classification_report(predicted_class_indices,lab)\n",
        "print('Confusion matrix report of the model : \\n{}'.format(cf_matrix))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-9y8PCI7r1L"
      },
      "source": [
        "print('Classification report of the model : \\n{}'.format(cf_report))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKmtmGT1FV9L"
      },
      "source": [
        "class_names = classes\n",
        "import itertools\n",
        "\n",
        "def plot_confusion_matrix(cf_matrix, classes, title='Confusion matrix', cmap=plt.cm.Blues,normalize=True):\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.grid(b=False)\n",
        "    plt.imshow(cf_matrix, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if class_names is not None:\n",
        "        tick_marks = np.arange(len(class_names))\n",
        "        plt.xticks(tick_marks, class_names, rotation=45)\n",
        "        plt.yticks(tick_marks, class_names)\n",
        "    if normalize:\n",
        "        cf_matrix = cf_matrix.astype('float') / cf_matrix.sum(axis=1)[:, np.newaxis]\n",
        "    \n",
        "    thresh = cf_matrix.max() / 1.5 if normalize else cf_matrix.max() / 2\n",
        "    for i, j in itertools.product(range(cf_matrix.shape[0]), range(cf_matrix.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.4f}\".format(cf_matrix[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"black\" if cf_matrix[i, j] > thresh else \"white\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cf_matrix[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"black\" if cf_matrix[i, j] > thresh else \"white\")\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.show()\n",
        "# compute confusion matrix\n",
        "cnf_matrix = confusion_matrix(predicted_class_indices,lab)\n",
        "np.set_printoptions(precision=np.random.randint(0,9))\n",
        "\n",
        "# plot confusion matrix\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=False ,title='Confusion matrix',cmap='Reds')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMswzhewG883"
      },
      "source": [
        "my_new_model.save_weights('model_wieghts.h5')\n",
        "my_new_model.save('Face_detection_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1N49PxiYMPj"
      },
      "source": [
        "import cv2\n",
        "import keras\n",
        "from google.colab.patches import cv2_imshow\n",
        "import keras\n",
        "from keras.models import load_model\n",
        "from keras.utils import CustomObjectScope\n",
        "from keras.initializers import glorot_uniform\n",
        "\n",
        "with CustomObjectScope({'GlorotUniform': glorot_uniform()}):\n",
        "        model = load_model(\"/content/Face_detection_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE7CYnkp1Zdp"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mNEoRjowC6O"
      },
      "source": [
        "image=cv2.imread('/content/gdrive/MyDrive/dataset1/with_mask/104-with-mask.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDQek4WyeFy0"
      },
      "source": [
        "prototxtPath = '/content/gdrive/MyDrive/face_detector/deploy.prototxt'\n",
        "weightsPath = '/content/gdrive/MyDrive/face_detector/res10_300x300_ssd_iter_140000.caffemodel'\n",
        "face_model = cv2.dnn.readNet(prototxtPath, weightsPath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeu8L0JN1kpF"
      },
      "source": [
        "height, width = image.shape[:2]\n",
        "blob = cv2.dnn.blobFromImage(image, 1.0, (224, 224), (104.0, 177.0, 123.0))\n",
        "face_model.setInput(blob)\n",
        "detections=face_model.forward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIEJEDQ619iX"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "threshold = 0.2\n",
        "person_with_mask = 0\n",
        "person_without_mask = 0\n",
        "for i in range(0, detections.shape[2]):\n",
        "    confidence = detections[0, 0, i, 2]\n",
        "    if confidence > 0.5:\n",
        "        box = detections[0, 0, i, 3:7] * np.array([width, height, width, height])\n",
        "        (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "        (startX, startY) = (max(0, startX), max(0, startY))\n",
        "        (endX, endY) = (min(width - 1, endX), min(height - 1, endY))\n",
        "\n",
        "        face = image[startY:endY, startX:endX]\n",
        "        face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
        "        face = cv2.resize(face, (224, 224))\n",
        "        face = img_to_array(face)\n",
        "        face = preprocess_input(face)\n",
        "        face = np.expand_dims(face, axis=0)\n",
        "\n",
        "        (mask, withoutMask) = model.predict(face)[0]\n",
        "        label = \"Mask\" if mask > withoutMask else \"No Mask\"\n",
        "        color = (0, 255, 0) if label == \"Mask\" else (0, 0, 255)\n",
        "\n",
        "        label = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
        "\n",
        "        cv2.putText(image, label, (startX, startY - 10),cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
        "        cv2.rectangle(image, (startX, startY), (endX, endY), color, 2)\n",
        "cv2_imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSFa5WZMetFt"
      },
      "source": [
        "|"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}